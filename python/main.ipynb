{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import load_data as ld\n",
    "import network_model as nt\n",
    "import utilities as tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare consts of main paths\n",
    "DATABASE = os.path.abspath('../../Database/')\n",
    "DATABASES_VERSIONS = os.listdir(DATABASE)\n",
    "# choose the path to right database version\n",
    "DATABASE_VERSION = 'V1'\n",
    "use_database = os.path.join(DATABASE, list(filter(lambda x: DATABASE_VERSION in x, DATABASES_VERSIONS))[0])\n",
    "datasets = ld.get_classes_names(use_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If datasets are already divided in to train and validation => run below, if not the next one or no one bc may be not written yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(use_database, datasets[0])\n",
    "path_valid = os.path.join(use_database, datasets[1])\n",
    "\n",
    "classes = ld.get_classes_names(path_train)\n",
    "\n",
    "# classes numbers\n",
    "classes_numbers = tools.make_labels_dict(classes)\n",
    "\n",
    "# train set\n",
    "imgs_train = []\n",
    "labels_train = []\n",
    "# validation set\n",
    "imgs_valid = []\n",
    "labels_valid = []\n",
    "# indicies for labels - kind of iterators\n",
    "label_train_start = 0\n",
    "label_valid_start = 0\n",
    "for class_name in classes:\n",
    "    # train images\n",
    "    temp_path = os.path.join(path_train, class_name)\n",
    "    temp = ld.load_images(temp_path)\n",
    "    imgs_train.extend(temp)\n",
    "    for i in range(label_train_start, label_train_start+len(temp)):\n",
    "        labels_train.append(classes_numbers[class_name])\n",
    "    label_train_start+=len(temp)\n",
    "    \n",
    "    # validation images\n",
    "    temp_path = os.path.join(path_valid, class_name)\n",
    "    temp = ld.load_images(temp_path)\n",
    "    imgs_valid.extend(temp)\n",
    "    for i in range(label_valid_start, label_valid_start+len(temp)):\n",
    "        labels_valid.append(classes_numbers[class_name])\n",
    "    label_valid_start+=len(temp)\n",
    "\n",
    "# shuffle data\n",
    "imgs_train, labels_train = tools.shuffle_data(imgs_train, labels_train)\n",
    "imgs_valid, labels_valid = tools.shuffle_data(imgs_valid, labels_valid)\n",
    "\n",
    "# convert to numpy array\n",
    "imgs_train = np.asarray(imgs_train)\n",
    "labels_train = np.asarray(labels_train)\n",
    "imgs_valid = np.asarray(imgs_valid)\n",
    "labels_valid = np.asarray(labels_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 60s 66ms/step - loss: 1.7869 - accuracy: 0.2629 - val_loss: 1.6031 - val_accuracy: 0.3721\n",
      "Epoch 2/150\n",
      "900/900 [==============================] - 60s 66ms/step - loss: 1.5874 - accuracy: 0.3757 - val_loss: 1.4602 - val_accuracy: 0.4389\n",
      "Epoch 3/150\n",
      "900/900 [==============================] - 60s 66ms/step - loss: 1.4694 - accuracy: 0.4284 - val_loss: 1.3349 - val_accuracy: 0.4858\n",
      "Epoch 4/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.3903 - accuracy: 0.4625 - val_loss: 1.3167 - val_accuracy: 0.4996\n",
      "Epoch 5/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.3222 - accuracy: 0.4892 - val_loss: 1.2576 - val_accuracy: 0.5203\n",
      "Epoch 6/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.2805 - accuracy: 0.5104 - val_loss: 1.1960 - val_accuracy: 0.5425\n",
      "Epoch 7/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.2415 - accuracy: 0.5220 - val_loss: 1.1770 - val_accuracy: 0.5476\n",
      "Epoch 8/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.2124 - accuracy: 0.5375 - val_loss: 1.1767 - val_accuracy: 0.5539\n",
      "Epoch 9/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 1.1717 - accuracy: 0.5556 - val_loss: 1.1401 - val_accuracy: 0.5662\n",
      "Epoch 10/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 1.1387 - accuracy: 0.5646 - val_loss: 1.1274 - val_accuracy: 0.5731\n",
      "Epoch 11/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 1.1006 - accuracy: 0.5783 - val_loss: 1.0952 - val_accuracy: 0.5853\n",
      "Epoch 12/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 1.0661 - accuracy: 0.5920 - val_loss: 1.0863 - val_accuracy: 0.5899\n",
      "Epoch 13/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 1.0324 - accuracy: 0.6075 - val_loss: 1.0736 - val_accuracy: 0.6008\n",
      "Epoch 14/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.9924 - accuracy: 0.6253 - val_loss: 1.0753 - val_accuracy: 0.6033\n",
      "Epoch 15/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.9596 - accuracy: 0.6378 - val_loss: 1.0738 - val_accuracy: 0.6035\n",
      "Epoch 16/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.9182 - accuracy: 0.6555 - val_loss: 1.0660 - val_accuracy: 0.6097\n",
      "Epoch 17/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.8832 - accuracy: 0.6696 - val_loss: 1.0532 - val_accuracy: 0.6062\n",
      "Epoch 18/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.8437 - accuracy: 0.6840 - val_loss: 1.0511 - val_accuracy: 0.6123\n",
      "Epoch 19/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.8059 - accuracy: 0.6954 - val_loss: 1.0897 - val_accuracy: 0.6036\n",
      "Epoch 20/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.7872 - accuracy: 0.7074 - val_loss: 1.0744 - val_accuracy: 0.6128\n",
      "Epoch 21/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.7537 - accuracy: 0.7237 - val_loss: 1.0777 - val_accuracy: 0.6113\n",
      "Epoch 22/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.7299 - accuracy: 0.7300 - val_loss: 1.0620 - val_accuracy: 0.6187\n",
      "Epoch 23/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.6990 - accuracy: 0.7418 - val_loss: 1.0768 - val_accuracy: 0.6175\n",
      "Epoch 24/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.6719 - accuracy: 0.7528 - val_loss: 1.1067 - val_accuracy: 0.6119\n",
      "Epoch 25/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 0.6623 - accuracy: 0.7570 - val_loss: 1.0960 - val_accuracy: 0.6138\n",
      "Epoch 26/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.6393 - accuracy: 0.7656 - val_loss: 1.1234 - val_accuracy: 0.6121\n",
      "Epoch 27/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.6249 - accuracy: 0.7728 - val_loss: 1.1337 - val_accuracy: 0.6158\n",
      "Epoch 28/150\n",
      "900/900 [==============================] - 60s 67ms/step - loss: 0.6093 - accuracy: 0.7763 - val_loss: 1.1251 - val_accuracy: 0.6072\n",
      "Epoch 29/150\n",
      "900/900 [==============================] - 61s 67ms/step - loss: 0.5963 - accuracy: 0.7837 - val_loss: 1.1520 - val_accuracy: 0.6100\n",
      "Epoch 30/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.5757 - accuracy: 0.7897 - val_loss: 1.1271 - val_accuracy: 0.6093\n",
      "Epoch 31/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.5648 - accuracy: 0.7943 - val_loss: 1.1348 - val_accuracy: 0.6113\n",
      "Epoch 32/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.5543 - accuracy: 0.7978 - val_loss: 1.1398 - val_accuracy: 0.6140\n",
      "Epoch 33/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.5399 - accuracy: 0.8027 - val_loss: 1.1669 - val_accuracy: 0.6083\n",
      "Epoch 34/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.5289 - accuracy: 0.8081 - val_loss: 1.1628 - val_accuracy: 0.6130\n",
      "Epoch 35/150\n",
      "900/900 [==============================] - 62s 68ms/step - loss: 0.5207 - accuracy: 0.8101 - val_loss: 1.1851 - val_accuracy: 0.6154\n",
      "Epoch 36/150\n",
      "900/900 [==============================] - 67s 74ms/step - loss: 0.5080 - accuracy: 0.8191 - val_loss: 1.1735 - val_accuracy: 0.6131\n",
      "Epoch 37/150\n",
      "900/900 [==============================] - 65s 72ms/step - loss: 0.5042 - accuracy: 0.8164 - val_loss: 1.1901 - val_accuracy: 0.6082\n",
      "Epoch 38/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.4926 - accuracy: 0.8243 - val_loss: 1.2027 - val_accuracy: 0.6126\n",
      "Epoch 39/150\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 0.4784 - accuracy: 0.8291 - val_loss: 1.1776 - val_accuracy: 0.6130\n",
      "Epoch 40/150\n",
      "900/900 [==============================] - 64s 71ms/step - loss: 0.4785 - accuracy: 0.8268 - val_loss: 1.1642 - val_accuracy: 0.6140\n",
      "Epoch 41/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4704 - accuracy: 0.8303 - val_loss: 1.1946 - val_accuracy: 0.6134\n",
      "Epoch 42/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4574 - accuracy: 0.8373 - val_loss: 1.2302 - val_accuracy: 0.6111\n",
      "Epoch 43/150\n",
      "900/900 [==============================] - 64s 71ms/step - loss: 0.4519 - accuracy: 0.8354 - val_loss: 1.2202 - val_accuracy: 0.6079\n",
      "Epoch 44/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4380 - accuracy: 0.8422 - val_loss: 1.2114 - val_accuracy: 0.6055\n",
      "Epoch 45/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4402 - accuracy: 0.8417 - val_loss: 1.2415 - val_accuracy: 0.6039\n",
      "Epoch 46/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4294 - accuracy: 0.8448 - val_loss: 1.2440 - val_accuracy: 0.6154\n",
      "Epoch 47/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4206 - accuracy: 0.8491 - val_loss: 1.2289 - val_accuracy: 0.6168\n",
      "Epoch 48/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4205 - accuracy: 0.8484 - val_loss: 1.2657 - val_accuracy: 0.6128\n",
      "Epoch 49/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4082 - accuracy: 0.8547 - val_loss: 1.2647 - val_accuracy: 0.6113\n",
      "Epoch 50/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.4010 - accuracy: 0.8555 - val_loss: 1.2554 - val_accuracy: 0.6177\n",
      "Epoch 51/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3965 - accuracy: 0.8575 - val_loss: 1.2736 - val_accuracy: 0.6208\n",
      "Epoch 52/150\n",
      "900/900 [==============================] - 63s 71ms/step - loss: 0.3920 - accuracy: 0.8586 - val_loss: 1.2972 - val_accuracy: 0.6089\n",
      "Epoch 53/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3888 - accuracy: 0.8623 - val_loss: 1.2688 - val_accuracy: 0.6213\n",
      "Epoch 54/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3729 - accuracy: 0.8657 - val_loss: 1.2422 - val_accuracy: 0.6181\n",
      "Epoch 55/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3724 - accuracy: 0.8666 - val_loss: 1.2672 - val_accuracy: 0.6131\n",
      "Epoch 56/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3669 - accuracy: 0.8686 - val_loss: 1.2725 - val_accuracy: 0.6151\n",
      "Epoch 57/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3656 - accuracy: 0.8690 - val_loss: 1.2781 - val_accuracy: 0.6133\n",
      "Epoch 58/150\n",
      "900/900 [==============================] - 64s 71ms/step - loss: 0.3631 - accuracy: 0.8716 - val_loss: 1.2940 - val_accuracy: 0.6144\n",
      "Epoch 59/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3636 - accuracy: 0.8686 - val_loss: 1.3149 - val_accuracy: 0.6093\n",
      "Epoch 60/150\n",
      "900/900 [==============================] - 63s 70ms/step - loss: 0.3582 - accuracy: 0.8713 - val_loss: 1.3324 - val_accuracy: 0.6103\n",
      "Epoch 61/150\n",
      "900/900 [==============================] - 64s 71ms/step - loss: 0.3446 - accuracy: 0.8767 - val_loss: 1.2969 - val_accuracy: 0.6121\n",
      "Epoch 62/150\n",
      "193/900 [=====>........................] - ETA: 45s - loss: 0.3352 - accuracy: 0.8781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m img_shape \u001b[39m=\u001b[39m imgs_train\u001b[39m.\u001b[39mshape\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39mbuild_neural_model(img_shape \u001b[39m=\u001b[39m (img_shape[\u001b[39m1\u001b[39m], img_shape[\u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m), nuber_of_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(classes))\n\u001b[1;32m----> 7\u001b[0m trained_model, history_model \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39;49mtrain_model(model, imgs_train\u001b[39m=\u001b[39;49mimgs_train, labels_train\u001b[39m=\u001b[39;49mlabels_train, imgs_val\u001b[39m=\u001b[39;49mimgs_valid, labels_val\u001b[39m=\u001b[39;49mlabels_valid, epochs_number\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\peter\\eng_thesis\\face-reader\\python\\network_model.py:117\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, imgs_train, labels_train, imgs_val, labels_val, epochs_number)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model: keras\u001b[39m.\u001b[39mSequential, imgs_train: np\u001b[39m.\u001b[39marray, labels_train: np\u001b[39m.\u001b[39marray, imgs_val: np\u001b[39m.\u001b[39marray, labels_val: np\u001b[39m.\u001b[39marray, epochs_number: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m keras\u001b[39m.\u001b[39mSequential:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     learned_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(imgs_train, labels_train, validation_data \u001b[39m=\u001b[39;49m (imgs_val, labels_val), epochs \u001b[39m=\u001b[39;49m epochs_number, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m model, learned_model\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\inz\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model training\n",
    "# Load the training data\n",
    "\n",
    "# # Fit the model\n",
    "img_shape = imgs_train.shape\n",
    "model = nt.build_neural_model(img_shape = (img_shape[1], img_shape[2], 1), nuber_of_classes = len(classes))\n",
    "trained_model, history_model = nt.train_model(model, imgs_train=imgs_train, labels_train=labels_train, imgs_val=imgs_valid, labels_val=labels_valid, epochs_number=150)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show trained model and evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialize model to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.serialize_model(trained_model, file_name = \"yt_guy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_model.history['accuracy'])\n",
    "plt.plot(history_model.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# eval = model.evaluate(imgs_test, labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deserialize model from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_access = cv2.VideoCapture(1)\n",
    "\n",
    "# ret, frame = cam_access.read()\n",
    "# plt.imshow(frame)\n",
    "\n",
    "# cam_access.release()\n",
    "\n",
    "# print((imgs_train.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "663c79c9021e5ebbf13463b9b3c2be3d8605a304ea48ff741684e427070422b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
